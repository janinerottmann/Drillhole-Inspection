{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled12.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPiYv+fvPqeuIeA/OgZXopW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janinerottmann/Drillhole-Inspection/blob/master/Performance_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXwkItGltZ63",
        "colab_type": "text"
      },
      "source": [
        "#Performance Evaluation\n",
        "The objective of this notebook is to find a suitable classifier for drill hole inspection. We compare the performance of a Support Vector machine (SVM), Random Forest (RF), Artificial Neural Network (ANN), K-Nearest-Neighbors (KNN) and Convolutional Neural Networks (CNN). The performace of each classifier is evaluated by Confusion Matrix, Balanced Accuracy, F1-Score and Log Loss. As features we use the Root Mean Square (RMS), maximum (MAX), crest-factor (CREST), kurtosis-factor (KURT) acceleration values in x, y and z direction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3aLuouvtXak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import save, load\n",
        "import torch\n",
        "from scipy.signal import spectrogram, stft\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import balanced_accuracy_score, f1_score, log_loss, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.python.keras.layers import concatenate\n",
        "from tensorflow.keras.layers import Dense, MaxPooling2D, Dropout, Flatten, Conv1D, MaxPooling1D, GaussianNoise, Conv2D, BatchNormalization, Activation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebWpVmZvtdsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "!pwd\n",
        "%cd ./drive/My\\ Drive\n",
        "datafolder = \"data2/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JUBQvs1tio3",
        "colab_type": "text"
      },
      "source": [
        "##1. Sample Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpDnM2gDuAHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#choose class balance and step size\n",
        "sampleSizeGood = 50\n",
        "sampleSizeBad = 50\n",
        "stepSize = 2\n",
        "drillNumber = 1\n",
        "#features = ['rmsAccX','rmsAccY','rmsAccZ']\n",
        "features = ['rmsAccX','rmsAccY','rmsAccZ', \n",
        "            'maxAccX', 'maxAccY', 'maxAccZ', \n",
        "            'crestAccX', 'crestAccY', 'crestAccZ', \n",
        "            'kurtAccX', 'kurtAccY', 'kurtAccZ']\n",
        "k = 5\n",
        "batchSize = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uJvQvPutwGV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#quality file\n",
        "file = datafolder + 'quality.csv'\n",
        "quality = pd.read_csv(file)\n",
        "quality = quality[['TeilNr', 'BohrlochNr', 'classifier', 'start_x', 'end_x', 'start_y', 'end_y']]\n",
        "all_drills = quality\n",
        "\n",
        "# get good and bad drills\n",
        "goodDrills = quality[quality['classifier'] == False]\n",
        "badDrills = quality[quality['classifier'] == True]\n",
        "\n",
        "# choose random good and bad drills\n",
        "random_good_drills = goodDrills.sample(n=sampleSizeGood)\n",
        "random_bad_drills = badDrills.sample(n=sampleSizeBad)\n",
        "all_drills = random_good_drills.append(random_bad_drills, ignore_index=True)\n",
        "\n",
        "all_drills['datapoints_x']=all_drills['end_x'] - all_drills['start_x']\n",
        "all_drills['datapoints_y']=all_drills['end_y'] - all_drills['start_y']\n",
        "\n",
        "#identify datapoints\n",
        "max_datapoints = all_drills.loc[:, ['datapoints_x', 'datapoints_y']].max().max()\n",
        "Ninterpolate = max_datapoints * 1.1\n",
        "\n",
        "#get filenames\n",
        "files = []\n",
        "parts = np.unique(all_drills['TeilNr'])\n",
        "\n",
        "for part in parts:\n",
        "  file = 'part' + str(int(part))+'.parq'\n",
        "  files = np.append(files, file)\n",
        "\n",
        "x_train_2D = []\n",
        "x_train_3D = []\n",
        "labels = []\n",
        "\n",
        "for i in all_drills.index.values:\n",
        "  \n",
        "  #identify part and drill number of randomly selected drill\n",
        "  row = all_drills[all_drills.index == i]\n",
        "  part = int(row['TeilNr'])\n",
        "  drill = int(row['BohrlochNr'])\n",
        "\n",
        "  #open file\n",
        "  file = 'part' + str(int(part))+'.parq'\n",
        "  df = pd.read_parquet(datafolder + file)\n",
        "\n",
        "  #locate sensor (v) and quality (q) data for each drill\n",
        "  v = df[(df['TeilNr'] == part) & (df['BohrlochNr'] == drill) & (df['drill'] == drillNumber)]\n",
        "  q = quality[(quality['TeilNr'] == part) & (quality['BohrlochNr'] == drill)]\n",
        "  \n",
        "\n",
        "  #get 2D-Tensor input\n",
        "  xout = np.linspace(0,len(v),int(Ninterpolate))\n",
        "  x_train_2D.append(np.concatenate([np.interp(xout, \n",
        "                                              np.arange(0,len(v)), \n",
        "                                              v[f].values).reshape(-1,1) for f in features], axis=0).reshape(1,-1))\n",
        "  #get 3D-Tensor input\n",
        "  xout = np.linspace(0,len(v),int(Ninterpolate))\n",
        "  x_train_3D.append(np.concatenate([np.interp(xout, \n",
        "                                              np.arange(0,len(v)), \n",
        "                                              v[f].values).reshape(1,-1,1) for f in features], axis=2))\n",
        "  \n",
        "  #get Output\n",
        "  labels.append(q.classifier)\n",
        "\n",
        "x_2D = np.concatenate(x_train_2D,axis=0)\n",
        "x_3D = np.concatenate(x_train_3D,axis=0)\n",
        "y = np.concatenate(labels,axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDqbazeuvI68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#optional save data to continue training later with the same datasampling\n",
        "save('data/x_2D.npy', x_2D)\n",
        "save('data/x_3D.npy', x_3D)\n",
        "save('data/y.npy', y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyhQFkVZvsFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#k fold cross validation\n",
        "kfold = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "for train_index, test_index in kfold.split(x_2D, y):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "\n",
        "for train_index, test_index in kfold.split(x_3D, y):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "\n",
        "x_train_2D, x_test_2D, y_train_2D, y_test_2D = x_2D[train_index], x_2D[test_index], y[train_index], y[test_index]\n",
        "x_train_3D, x_test_3D, y_train_3D, y_test_3D = x_3D[train_index], x_3D[test_index], y[train_index], y[test_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COs5PPiGv9Sv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#preprocessing\n",
        "sc_x_2D = StandardScaler()\n",
        "x_train_2D = sc_x_2D.fit_transform(x_train_2D)\n",
        "x_test_2D = sc_x_2D.transform(x_test_2D)\n",
        "\n",
        "sc_x_3D = StandardScaler()\n",
        "x_train_3D = sc_x_3D.fit_transform(x_train_3D.reshape(-1, x_train_3D.shape[-1])).reshape(x_train_3D.shape)\n",
        "x_test_3D = sc_x_3D.transform(x_test_3D.reshape(-1, x_test_3D.shape[-1])).reshape(x_test_3D.shape)\n",
        "\n",
        "x_train_2D = preprocessing.normalize(x_train_2D)\n",
        "x_test_2D = preprocessing.normalize(x_test_2D)\n",
        "\n",
        "x_train_3D = preprocessing.normalize(x_train_3D.reshape(-1, x_train_3D.shape[-1])).reshape(x_train_3D.shape)\n",
        "x_test_3D = preprocessing.normalize(x_test_3D.reshape(-1, x_test_3D.shape[-1])).reshape(x_test_3D.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "895KwU3lwImk",
        "colab_type": "text"
      },
      "source": [
        "##2. Short Time Fourier Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfLgq51p5FuP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#STFT\n",
        "x_four = []\n",
        "for bl in range(x_3D.shape[0]): # first dimension of tensor: drill holes\n",
        "    tmpfft = [] ## zwischenspeicher für die verschiednen features\n",
        "    for f in range(x_3D.shape[2]): #third dimension: features\n",
        "        fft = np.abs(np.asarray(stft(x_3D[bl,:,f],fs=4096,nfft=256)[2])) # fs = Abtastrate in Herz\n",
        "        tmpfft.append(fft.reshape(fft.shape[0],fft.shape[1],1)) \n",
        "    tmpfft = np.concatenate(tmpfft,axis=2) ## zu einer Matrix zusammenfügen\n",
        "    x_four.append(tmpfft.reshape(1,tmpfft.shape[0],tmpfft.shape[1],tmpfft.shape[2]))\n",
        "x_four = np.concatenate(x_four,axis=0)\n",
        "\n",
        "x_four = 10. * np.log10(x_four+np.finfo(float).eps)\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
        "\n",
        "for train_index, test_index in kfold.split(x_four, y):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "\n",
        "x_train_four, x_test_four, y_train_four, y_test_four = x_four[train_index], x_four[test_index], y[train_index], y[test_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pneTWdWBwJt5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot spectogram\n",
        "nfft=256\n",
        "fs=32000\n",
        "\n",
        "neg_example = random.sample(list(np.where(y==1)[0]),1)[0]\n",
        "pos_example = random.sample(list(np.where(y==0)[0]),1)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1cHRexJwbAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pre- and finedrill\n",
        "fig, axes = plt.subplots(2, 1, figsize=(16,8))\n",
        "axes[0].plot(x_3D[pos_example])\n",
        "axes[0].set_title('Positive example')\n",
        "axes[1].plot(x_3D[neg_example])\n",
        "axes[1].set_title('Negative example')  \n",
        "_ = fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ch9B_br5wZ7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pre- and finedrill as spectogram\n",
        "fig, axes = plt.subplots(2, 1,figsize=(16,8))\n",
        "axes[0].specgram(x_four[pos_example,:,-1].flatten(), Fs=fs, NFFT=nfft)\n",
        "axes[0].set_title('Positive examples')\n",
        "axes[1].specgram(x_four[neg_example,:,-1].flatten(), Fs=fs, NFFT=nfft)\n",
        "axes[1].set_title('Negative examples')\n",
        "_=fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Oob1DZlw0tG",
        "colab_type": "text"
      },
      "source": [
        "##3. Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXbPTz4ExzUo",
        "colab_type": "text"
      },
      "source": [
        "###3.1 SVM, ANN, RF, KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Fw1LpxwxDzx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_weight = {0: 0.25, 1:0.75}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykwv16taxIkp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RBF_SVC = SVC(class_weight=class_weight)\n",
        "MLPClassifier = MLPClassifier()\n",
        "RandomForestClassifier = RandomForestClassifier(class_weight=class_weight)\n",
        "KNeighborsClassifier = KNeighborsClassifier()\n",
        "\n",
        "classifiers = [RBF_SVC,\n",
        "               MLPClassifier,\n",
        "               RandomForestClassifier,\n",
        "               KNeighborsClassifier]\n",
        "\n",
        "names = [\"RBF SVM\",\n",
        "         \"Neural Net\",\n",
        "         \"Random Forest\",\n",
        "         \"Nearest Neighbors\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuidOWQxw8bA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def algorithm_pipeline(x_train, y_train, model, param_grid, name):\n",
        "    grid = GridSearchCV(estimator=model,\n",
        "                        param_grid=param_grid, \n",
        "                        cv=2, \n",
        "                        n_jobs=-1, \n",
        "                        scoring='accuracy',\n",
        "                        verbose=0)\n",
        "    grid.fit(x_train, y_train)\n",
        "    best_param = grid.best_params_\n",
        "    return best_param"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrvpxAtkxM6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#parameters for tuning\n",
        "\n",
        "svm = {'C': [1, 2, 3],  # default = 1\n",
        "       'gamma': [0.1, 0.01, 0.001, 0.0001]} #default = scale: 0.001\n",
        "\n",
        "mlp = {'solver': ['sgd', 'adam', 'lbfgs'], #default = adam\n",
        "       'alpha': [0.001, 0.01, 0.1], # default = 0.001\n",
        "       'learning_rate' : ['constant', 'invscaling', 'adaptive'], #default = constant\n",
        "       'max_iter': [150,200,250] #default = 200\n",
        "       }\n",
        "\n",
        "rf = {'n_estimators': [100, 150], # default = 100\n",
        "      'min_samples_split': [1,2,3], # default = 2\n",
        "      'min_samples_leaf': [1,2,3]} \n",
        "\n",
        "knn = {'n_neighbors': [3,5,7,10], #default = 5\n",
        "       'leaf_size' : [10,20,30,40]} #default = 30\n",
        "\n",
        "params = [svm, mlp, rf, knn]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7L4JTDrZxU5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res_list = []\n",
        "\n",
        "for model, name, param in zip(classifiers, names, params):\n",
        "\n",
        "  #hyperparameter tuning\n",
        "  best_params = algorithm_pipeline(x_train_2D, y_train_2D, model, param, name)\n",
        "  for key, variable in best_params.items():\n",
        "    setattr(model, key, variable)\n",
        "  print(best_params)\n",
        "  \n",
        "  #fit\n",
        "  model.fit(x_train_2D, y_train_2D)\n",
        "  \n",
        "  #predict\n",
        "  y_pred = model.predict(x_test_2D)\n",
        "\n",
        "  #metrics\n",
        "  res =[name,\n",
        "        balanced_accuracy_score(y_test_2D, y_pred)*100,\n",
        "        precision_score(y_test_2D, y_pred)*100,\n",
        "        recall_score(y_test_2D, y_pred)*100,\n",
        "        f1_score(y_test_2D, y_pred)*100,\n",
        "        log_loss(y_test_2D, y_pred),\n",
        "        confusion_matrix(y_test_2D, y_pred)[0][0],\n",
        "        confusion_matrix(y_test_2D, y_pred)[0][1],\n",
        "        confusion_matrix(y_test_2D, y_pred)[1][0],\n",
        "        confusion_matrix(y_test_2D, y_pred)[1][1],\n",
        "        ]\n",
        "  res_list.append(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odFrJy6xxcSP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(res_list, columns= [\"Model\", \n",
        "                                      \"Balanced Accuracy\", \n",
        "                                      \"Precision\", \n",
        "                                      \"Recall\", \n",
        "                                      \"F1\", \n",
        "                                      \"Log Loss\", \n",
        "                                      \"TN\", #true negatives\n",
        "                                      \"FP\", #false positives\n",
        "                                      \"FN\", #false negatives\n",
        "                                      \"TP\"  #true positives\n",
        "                                      ]).round(decimals=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv_nv4d_x8uZ",
        "colab_type": "text"
      },
      "source": [
        "###3.2 CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDf8HAIFxwK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def CNN_model_four():\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(GaussianNoise( 0.01, input_shape=x_train_four.shape[-3:]))\n",
        "    model.add(Conv2D(32, (7, 7), padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(5, 5), padding = 'same'))\n",
        "    model.add(Dropout(0.3))\n",
        "    \n",
        "    model.add(Conv2D(64, (7, 7), padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(4, 100), padding = 'same'))\n",
        "    model.add(Dropout(0.3))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', \n",
        "                  optimizer=\"adam\",                       \n",
        "                  metrics='accuracy')\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CefGGBxEyAR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CNN_Four = CNN_model_four()\n",
        "\n",
        "CNN_history_four = CNN_Four.fit(x_train_four, y_train_four, \n",
        "                                batch_size = batchSize, \n",
        "                                epochs=100, \n",
        "                                validation_data=(x_test_four,y_test_four),\n",
        "                                verbose=0)\n",
        "\n",
        "y_pred_four = CNN_Four.predict_classes(x_test_four, verbose=0, batch_size=batchSize)\n",
        "\n",
        "res_CNN = ['CNN',\n",
        "            balanced_accuracy_score(y_test_four, y_pred_four)*100,\n",
        "            precision_score(y_test_four, y_pred_four)*100,\n",
        "            recall_score(y_test_four, y_pred_four)*100,\n",
        "            f1_score(y_test_four, y_pred_four)*100,\n",
        "            log_loss(y_test_four, y_pred_four),\n",
        "            confusion_matrix(y_test_four, y_pred_four)[0][0],\n",
        "            confusion_matrix(y_test_four, y_pred_four)[0][1],\n",
        "            confusion_matrix(y_test_four, y_pred_four)[1][0],\n",
        "            confusion_matrix(y_test_four, y_pred_four)[1][1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKkI9UDfyYXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_CNN = pd.DataFrame(res_CNN, index=[\"Model\", \n",
        "                                      \"Balanced Accuracy\", \n",
        "                                      \"Precision\", \n",
        "                                      \"Recall\", \n",
        "                                      \"F1\", \n",
        "                                      \"Log Loss\", \n",
        "                                      \"TP\", #true positives\n",
        "                                      \"FP\", #false positives\n",
        "                                      \"FN\", #false negatives\n",
        "                                      \"TN\"  #true negatives\n",
        "                                       ]).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmCfwE8AzVw1",
        "colab_type": "text"
      },
      "source": [
        "##4. Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gw1pcSh9zXFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.append(df_CNN)\n",
        "df = df.sort_values(by=['Balanced Accuracy'], ascending=False)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}